{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20dac201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: time_series_county_cases.csv\n",
      "county      Andrews, TX  Atascosa, TX  Bailey, TX  Bell, TX  Bexar, TX  Borden, TX  Brazoria, TX  Brewster, TX  Brown, TX  Carson, TX  Cochran, TX  Collin, TX  Dallam, TX  Dallas, TX  Dawson, TX  Denton, TX  Eastland, TX  Ector, TX  El Paso, TX  Erath, TX  Fannin, TX  Fort Bend, TX  Gaines, TX  Garza, TX  Hale, TX  Hardeman, TX  Harris, TX  Harrison, TX  Hays, TX  Hockley, TX  Lamar, TX  Lamb, TX  Lubbock, TX  Lynn, TX  Martin, TX  McLennan, TX  Midland, TX  Parmer, TX  Potter, TX  Randall, TX  Reeves, TX  Rockwall, TX  Scurry, TX  Shackelford, TX  Tarrant, TX  Terry, TX  Travis, TX  Upshur, TX  Williamson, TX  Yoakum, TX\n",
      "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "2024-04-11          1.0           NaN         NaN       NaN        NaN         NaN           NaN           NaN        NaN         NaN          NaN         NaN         NaN         NaN         NaN         NaN           NaN        NaN          NaN        NaN         NaN            NaN         NaN        NaN       NaN           NaN         NaN           NaN       NaN          NaN        NaN       NaN          NaN       NaN         NaN           NaN          NaN         NaN         NaN          NaN         NaN           NaN         NaN              NaN          NaN        NaN         NaN         NaN             NaN         NaN\n",
      "2025-02-24          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          0.0         0.0         0.0         0.0         6.0         0.0           0.0        1.0          0.0        0.0         0.0            0.0        57.0        0.0       0.0           0.0         0.0           0.0       0.0          0.0        0.0       0.0          1.0       1.0         0.0           0.0          0.0         0.0         0.0          0.0         0.0           0.0         0.0              0.0          0.0       20.0         0.0         0.0             0.0         4.0\n",
      "2025-02-25          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          0.0         0.0         4.0         0.0         7.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0        80.0        0.0       0.0           0.0         0.0           0.0       0.0          0.0        0.0       0.0          1.0       1.0         3.0           0.0          0.0         0.0         0.0          0.0         0.0           0.0         0.0              0.0          0.0       21.0         0.0         0.0             0.0         5.0\n",
      "2025-02-28          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          0.0         0.0         4.0         0.0         8.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0        98.0        0.0       0.0           0.0         0.0           0.0       0.0          0.0        0.0       0.0          2.0       2.0         3.0           0.0          0.0         0.0         0.0          0.0         0.0           0.0         0.0              0.0          0.0       21.0         0.0         0.0             0.0         6.0\n",
      "2025-03-04          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          0.0         0.0         4.0         0.0         9.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0       107.0        0.0       0.0           0.0         2.0           0.0       0.0          0.0        0.0       0.0          3.0       2.0         3.0           0.0          0.0         0.0         0.0          0.0         0.0           1.0         0.0              0.0          0.0       22.0         1.0         0.0             0.0         7.0\n",
      "2025-03-07          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          0.0         0.0         5.0         0.0         9.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0       137.0        0.0       0.0           0.0         2.0           0.0       0.0          0.0        0.0       0.0          3.0       2.0         3.0           0.0          0.0         0.0         0.0          0.0         0.0           1.0         0.0              0.0          0.0       29.0         1.0         0.0             0.0         8.0\n",
      "2025-03-11          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          0.0         0.0         5.0         0.0        10.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0       156.0        0.0       0.0           0.0         2.0           0.0       0.0          0.0        0.0       0.0          3.0       2.0         3.0           0.0          0.0         0.0         0.0          0.0         0.0           1.0         0.0              0.0          0.0       32.0         1.0         0.0             0.0        10.0\n",
      "2025-03-21          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          7.0         0.0         6.0         0.0        13.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0       211.0        1.0       1.0           0.0         3.0           0.0       0.0          1.0        5.0       0.0          8.0       2.0         3.0           0.0          1.0         0.0         0.0          1.0         0.0           1.0         0.0              0.0          0.0       37.0         1.0         0.0             0.0        12.0\n",
      "2025-03-25          0.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        0.0         0.0          7.0         0.0         6.0         0.0        13.0         0.0           0.0        2.0          0.0        0.0         0.0            0.0       226.0        1.0       1.0           0.0         3.0           0.0       0.0          1.0        5.0       1.0         10.0       2.0         3.0           0.0          1.0         0.0         0.0          1.0         0.0           1.0         0.0              0.0          0.0       37.0         1.0         0.0             0.0        13.0\n",
      "2025-04-04          1.0           0.0         0.0       0.0        0.0         0.0           0.0           0.0        1.0         0.0          9.0         0.0         7.0         0.0        20.0         0.0           0.0        8.0          0.0        1.0         0.0            1.0       315.0        2.0       3.0           0.0         3.0           0.0       0.0          3.0       11.0       1.0         33.0       2.0         3.0           0.0          1.0         0.0         0.0          1.0         0.0           1.0         0.0              0.0          0.0       43.0         1.0         0.0             0.0        17.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# --- OPTION A: read from URL (works in a normal Python environment) ---\n",
    "URL = \"https://raw.githubusercontent.com/gauravfs-14/measles-dashboard/refs/heads/master/src/data/json/cases_over_time.json\"\n",
    "use_url = True  # set to False to use OPTION B below\n",
    "\n",
    "import urllib.request, ssl\n",
    "ctx = ssl.create_default_context()\n",
    "with urllib.request.urlopen(URL, context=ctx) as resp:\n",
    "    data = json.loads(resp.read().decode(\"utf-8\"))\n",
    "# ---- Build long table: (date, county, case) ----\n",
    "rows = []\n",
    "for item in data:\n",
    "    county = item[\"county\"]\n",
    "    for rec in item[\"cases\"]:\n",
    "        rows.append({\"date\": rec[\"date\"], \"county\": county, \"case\": rec[\"case\"]})\n",
    "\n",
    "long_df = pd.DataFrame(rows)\n",
    "\n",
    "# Ensure date is proper and sorted\n",
    "long_df[\"date\"] = pd.to_datetime(long_df[\"date\"])\n",
    "long_df = long_df.sort_values([\"date\", \"county\"])\n",
    "\n",
    "# ---- Pivot to wide: rows = dates, cols = counties ----\n",
    "wide_df = long_df.pivot_table(\n",
    "    index=\"date\",\n",
    "    columns=\"county\",\n",
    "    values=\"case\",\n",
    "    aggfunc=\"first\"  # in case duplicates exist, take the first\n",
    ")\n",
    "\n",
    "# Optional: sort columns alphabetically\n",
    "wide_df = wide_df.sort_index(axis=1)\n",
    "\n",
    "# Optional: format date as YYYY-MM-DD string for Excel-friendliness\n",
    "out = wide_df.copy()\n",
    "out.index = out.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Save and also show a small preview\n",
    "csv_path = \"time_series_county_cases.csv\"\n",
    "out.to_csv(csv_path, index_label=\"date\")\n",
    "\n",
    "print(\"Saved:\", csv_path)\n",
    "print(out.head(10).to_string())  # preview first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3730ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrews, TX\n",
      "Atascosa, TX\n",
      "Bailey, TX\n",
      "Bell, TX\n",
      "Bexar, TX\n",
      "Borden, TX\n",
      "Brazoria, TX\n",
      "Brewster, TX\n",
      "Brown, TX\n",
      "Carson, TX\n",
      "Cochran, TX\n",
      "Collin, TX\n",
      "Dallam, TX\n",
      "Dallas, TX\n",
      "Dawson, TX\n",
      "Denton, TX\n",
      "Eastland, TX\n",
      "Ector, TX\n",
      "El Paso, TX\n",
      "Erath, TX\n",
      "Fannin, TX\n",
      "Fort Bend, TX\n",
      "Gaines, TX\n",
      "Garza, TX\n",
      "Hale, TX\n",
      "Hardeman, TX\n",
      "Harris, TX\n",
      "Harrison, TX\n",
      "Hays, TX\n",
      "Hockley, TX\n",
      "Lamar, TX\n",
      "Lamb, TX\n",
      "Lubbock, TX\n",
      "Lynn, TX\n",
      "Martin, TX\n",
      "McLennan, TX\n",
      "Midland, TX\n",
      "Parmer, TX\n",
      "Potter, TX\n",
      "Randall, TX\n",
      "Reeves, TX\n",
      "Rockwall, TX\n",
      "Scurry, TX\n",
      "Shackelford, TX\n",
      "Tarrant, TX\n",
      "Terry, TX\n",
      "Travis, TX\n",
      "Upshur, TX\n",
      "Williamson, TX\n",
      "Yoakum, TX\n",
      "Andrews, TX\tAtascosa, TX\tBailey, TX\tBell, TX\tBexar, TX\tBorden, TX\tBrazoria, TX\tBrewster, TX\tBrown, TX\tCarson, TX\tCochran, TX\tCollin, TX\tDallam, TX\tDallas, TX\tDawson, TX\tDenton, TX\tEastland, TX\tEctor, TX\tEl Paso, TX\tErath, TX\tFannin, TX\tFort Bend, TX\tGaines, TX\tGarza, TX\tHale, TX\tHardeman, TX\tHarris, TX\tHarrison, TX\tHays, TX\tHockley, TX\tLamar, TX\tLamb, TX\tLubbock, TX\tLynn, TX\tMartin, TX\tMcLennan, TX\tMidland, TX\tParmer, TX\tPotter, TX\tRandall, TX\tReeves, TX\tRockwall, TX\tScurry, TX\tShackelford, TX\tTarrant, TX\tTerry, TX\tTravis, TX\tUpshur, TX\tWilliamson, TX\tYoakum, TX\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib.request, ssl\n",
    "\n",
    "URL = \"https://raw.githubusercontent.com/gauravfs-14/measles-dashboard/refs/heads/master/src/data/json/cases_over_time.json\"\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "with urllib.request.urlopen(URL, context=ctx) as resp:\n",
    "    data = json.loads(resp.read().decode(\"utf-8\"))\n",
    "\n",
    "# extract sorted list of unique counties\n",
    "counties = sorted({item[\"county\"] for item in data})\n",
    "\n",
    "# print vertical list\n",
    "print(\"\\n\".join(counties))\n",
    "\n",
    "# OR, if you want to copy horizontally for Excel:\n",
    "print(\"\\t\".join(counties))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de82d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved expanded daily file: C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\infection_county_cases.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\INFECTIONS BACKUP.csv\")\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 1. Parse dates\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df = df.dropna(subset=['date']).sort_values('date')\n",
    "\n",
    "# 2. Create continuous date range\n",
    "full_dates = pd.date_range(df['date'].min(), df['date'].max(), freq='D')\n",
    "full_df = pd.DataFrame({'date': full_dates})\n",
    "\n",
    "# 3. Merge with your original infection data\n",
    "merged = full_df.merge(df, on='date', how='left')\n",
    "\n",
    "# 4. Fill missing county values with 0\n",
    "county_cols = [c for c in merged.columns if c != 'date']\n",
    "merged[county_cols] = merged[county_cols].fillna(0).astype(int)\n",
    "\n",
    "# 5. Save for future modeling\n",
    "out = Path(r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\infection_county_cases.csv\")\n",
    "merged.to_csv(out, index=False)\n",
    "print(f\"Saved expanded daily file: {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4be4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\time_series_county_cases.csv\")\n",
    "\n",
    "def make_recoveries_from_infections(\n",
    "    infections_csv: str,\n",
    "    out_csv: str,\n",
    "    shift_days: int = 10,\n",
    "    exceptions: list | None = None,\n",
    "    right_censor_to_last: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a recoveries dataset by shifting infections forward by `shift_days`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infections_csv : str\n",
    "        Path to the infections CSV (wide: 'date' + county columns). Must include every day.\n",
    "    out_csv : str\n",
    "        Path to write the recoveries CSV (wide).\n",
    "    shift_days : int\n",
    "        Number of days to shift infections forward to represent recovery.\n",
    "    exceptions : list[(date, county, subtract_n)]\n",
    "        e.g., [(\"2025-03-04\",\"Gaines\",1), (\"2025-04-04\",\"Gaines\",1)]\n",
    "    right_censor_to_last : bool\n",
    "        If True, if (infection date + shift_days) exceeds the last date, assign to last date.\n",
    "        If False, drop those (not closed).\n",
    "    \"\"\"\n",
    "    # path = Path(infections_csv)\n",
    "    df = pd.read_csv(path)\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.dropna(subset=['date']).sort_values('date').reset_index(drop=True)\n",
    "    county_cols = [c for c in df.columns if c != 'date']\n",
    "    for c in county_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    min_d, max_d = df['date'].min(), df['date'].max()\n",
    "\n",
    "    # Long infections\n",
    "    long_inf = df.melt(id_vars='date', var_name='county', value_name='infected')\n",
    "    long_inf = long_inf[long_inf['infected'] > 0].copy()\n",
    "\n",
    "    def map_recovery_date(d):\n",
    "        rec = d + timedelta(days=shift_days)\n",
    "        if rec <= max_d:\n",
    "            return rec\n",
    "        return max_d if right_censor_to_last else pd.NaT\n",
    "\n",
    "    long_inf['recovery_date'] = long_inf['date'].apply(map_recovery_date)\n",
    "    if not right_censor_to_last:\n",
    "        long_inf = long_inf.dropna(subset=['recovery_date'])\n",
    "\n",
    "    recovered_long = (long_inf\n",
    "                      .groupby(['recovery_date','county'], as_index=False)['infected']\n",
    "                      .sum()\n",
    "                      .rename(columns={'infected':'recovered'}))\n",
    "\n",
    "    # Apply exceptions (subtract from recovery on (inf_date + shift_days))\n",
    "    if exceptions:\n",
    "        for exc_date, county_name, subtract_n in exceptions:\n",
    "            exc_date = pd.to_datetime(exc_date)\n",
    "            rec_date = exc_date + timedelta(days=shift_days)\n",
    "            if rec_date > max_d and right_censor_to_last:\n",
    "                rec_date = max_d\n",
    "            if rec_date < min_d or rec_date > max_d:\n",
    "                continue\n",
    "            mask = (recovered_long['recovery_date']==rec_date) & (recovered_long['county']==county_name)\n",
    "            if not mask.any():\n",
    "                recovered_long = pd.concat([\n",
    "                    recovered_long,\n",
    "                    pd.DataFrame([{'recovery_date': rec_date, 'county': county_name, 'recovered': -subtract_n}])\n",
    "                ], ignore_index=True)\n",
    "            else:\n",
    "                recovered_long.loc[mask, 'recovered'] = recovered_long.loc[mask, 'recovered'] - subtract_n\n",
    "\n",
    "    # Back to wide aligned to original date index\n",
    "    recovered_wide = (recovered_long\n",
    "                      .pivot(index='recovery_date', columns='county', values='recovered')\n",
    "                      .fillna(0).astype(int)\n",
    "                      .reindex(df['date'].unique(), fill_value=0)\n",
    "                      .rename_axis('date')\n",
    "                      .reset_index())\n",
    "\n",
    "    # Keep original columns/order\n",
    "    for c in county_cols:\n",
    "        if c not in recovered_wide.columns:\n",
    "            recovered_wide[c] = 0\n",
    "    recovered_wide = recovered_wide[['date'] + county_cols]\n",
    "    recovered_wide[county_cols] = recovered_wide[county_cols].astype(int)\n",
    "\n",
    "    Path(out_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    recovered_wide.to_csv(out_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b2c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-day recoveries (your case)\n",
    "make_recoveries_from_infections(\n",
    "    infections_csv=r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\time_series_county_cases.csv\",\n",
    "    out_csv=r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\recov_og_county_cases.csv\",\n",
    "    shift_days=10,\n",
    "    exceptions=[(\"2025-03-04\",\"Gaines\",1), (\"2025-04-04\",\"Gaines\",1)],\n",
    "    right_censor_to_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77e606",
   "metadata": {},
   "source": [
    "creating raw weekly infection county data by aggregating each week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1097ce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly aggregated infections saved to C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\weekly_infection_county_cases.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_path = r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\infection_county_cases.csv\"\n",
    "output_path = r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\weekly_infection_county_cases.csv\"\n",
    "\n",
    "# Read raw daily data\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Resample weekly and sum all columns (all counties)\n",
    "weekly_df = df.resample('W').sum()\n",
    "\n",
    "# Reset index to return date as a column\n",
    "weekly_df = weekly_df.reset_index()\n",
    "\n",
    "# Save weekly aggregated data to CSV\n",
    "weekly_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Weekly aggregated infections saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11a06c",
   "metadata": {},
   "source": [
    "aggregate data every 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "765ed5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twice weekly aggregated infections saved to C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\twice_weekly_death_county_cases.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_path = r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\death_by_county.csv\"\n",
    "output_path = r\"C:\\Users\\msnin\\Downloads\\Oden\\Oden-github\\Measles Model\\Datasets Used\\twice_weekly_death_county_cases.csv\"\n",
    "\n",
    "# Read raw daily data\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Resample approx twice weekly (every 3 days)\n",
    "twice_weekly_df = df.resample('4D').sum()\n",
    "\n",
    "# Reset index to return date as a column\n",
    "twice_weekly_df = twice_weekly_df.reset_index()\n",
    "\n",
    "# Save twice weekly aggregated data to CSV\n",
    "twice_weekly_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Twice weekly aggregated infections saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
